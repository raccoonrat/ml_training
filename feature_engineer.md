

## ğŸ”„ æ•°æ®è½¬æ¢æµç¨‹åˆ†æ

### 1. **åŸå§‹æ•°æ®ç»“æ„å®šä¹‰**

é¡¹ç›®ä½¿ç”¨ `FeatureVector` æ•°æ®ç±»æ¥å®šä¹‰åŸå§‹æ€§èƒ½æŒ‡æ ‡ï¼š

```python
@dataclass
class FeatureVector:
    """ç‰¹å¾å‘é‡æ•°æ®ç±»"""
    time: int = 0                    # æ—¶é—´æˆ³
    node_id: str = ""                # èŠ‚ç‚¹ID
    power_consumption: float = 0.0   # åŠŸè€—ï¼ˆç›®æ ‡å˜é‡ï¼‰

    # ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼ˆ20ä¸ªç‰¹å¾ï¼‰
    cpu_util: float = 0.0            # CPUä½¿ç”¨ç‡
    mem_util: float = 0.0            # å†…å­˜ä½¿ç”¨ç‡
    disk_io: float = 0.0             # ç£ç›˜I/O
    net_io: float = 0.0              # ç½‘ç»œI/O
    gpu_util: float = 0.0            # GPUä½¿ç”¨ç‡
    gpu_mem: float = 0.0             # GPUå†…å­˜ä½¿ç”¨ç‡
    temp_cpu: float = 0.0            # CPUæ¸©åº¦
    temp_gpu: float = 0.0            # GPUæ¸©åº¦
    fan_speed: float = 0.0           # é£æ‰‡è½¬é€Ÿ
    voltage: float = 0.0             # ç”µå‹
    current: float = 0.0             # ç”µæµ
    frequency: float = 0.0           # é¢‘ç‡
    cache_miss: float = 0.0          # ç¼“å­˜æœªå‘½ä¸­
    cache_hit: float = 0.0           # ç¼“å­˜å‘½ä¸­
    context_switch: float = 0.0      # ä¸Šä¸‹æ–‡åˆ‡æ¢
    page_fault: float = 0.0          # é¡µé¢é”™è¯¯
    interrupts: float = 0.0          # ä¸­æ–­æ•°
    load_avg: float = 0.0            # è´Ÿè½½å¹³å‡å€¼
    process_count: float = 0.0       # è¿›ç¨‹æ•°
    thread_count: float = 0.0        # çº¿ç¨‹æ•°
```

### 2. **ç‰¹å¾åˆ—å®šä¹‰**

```python
# å®šä¹‰ç‰¹å¾åˆ—åï¼ˆ20ä¸ªç‰¹å¾ï¼‰
FEATURE_COLUMNS = [
    'cpu_util', 'mem_util', 'disk_io', 'net_io', 'gpu_util', 'gpu_mem',
    'temp_cpu', 'temp_gpu', 'fan_speed', 'voltage', 'current', 'frequency',
    'cache_miss', 'cache_hit', 'context_switch', 'page_fault', 'interrupts',
    'load_avg', 'process_count', 'thread_count'
]

# ç›®æ ‡åˆ—å
TARGET_COLUMN = 'power_consumption'

# å…ƒæ•°æ®åˆ—å
METADATA_COLUMNS = ['time', 'node_id']
```

### 3. **æ•°æ®é¢„å¤„ç†æµç¨‹**

#### 3.1 **ç¼ºå¤±å€¼å¤„ç†**

```python
def _handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
    # 1. å‰å‘å¡«å……
    df[FEATURE_COLUMNS + [TARGET_COLUMN]] = df[FEATURE_COLUMNS + [TARGET_COLUMN]].fillna(method='ffill')

    # 2. åå‘å¡«å……
    df[FEATURE_COLUMNS + [TARGET_COLUMN]] = df[FEATURE_COLUMNS + [TARGET_COLUMN]].fillna(method='bfill')

    # 3. å‡å€¼å¡«å……
    df[FEATURE_COLUMNS + [TARGET_COLUMN]] = df[FEATURE_COLUMNS + [TARGET_COLUMN]].fillna(
        df[FEATURE_COLUMNS + [TARGET_COLUMN]].mean()
    )
```

#### 3.2 **ç‰¹å¾å·¥ç¨‹**

```python
def _feature_engineering(self, df: pd.DataFrame) -> pd.DataFrame:
    # 1. æ—¶é—´ç‰¹å¾
    df['timestamp'] = pd.to_datetime(df['time'], unit='s')
    df['hour'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

    # 2. æ»åç‰¹å¾
    for col in FEATURE_COLUMNS[:5]:
        df[f'{col}_lag1'] = df[col].shift(1)
        df[f'{col}_lag2'] = df[col].shift(2)

    # 3. æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
    for col in FEATURE_COLUMNS[:3]:
        df[f'{col}_rolling_mean'] = df[col].rolling(window=5, min_periods=1).mean()
        df[f'{col}_rolling_std'] = df[col].rolling(window=5, min_periods=1).std()

    # 4. äº¤äº’ç‰¹å¾
    df['cpu_mem_interaction'] = df['cpu_util'] * df['mem_util']
    df['gpu_util_mem_interaction'] = df['gpu_util'] * df['gpu_mem']
```

#### 3.3 **å¼‚å¸¸å€¼å¤„ç†**

```python
def _handle_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
    # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼
    for col in FEATURE_COLUMNS + [TARGET_COLUMN]:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # å°†å¼‚å¸¸å€¼é™åˆ¶åœ¨è¾¹ç•Œå†…
        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)
```

#### 3.4 **æ•°æ®æ ‡å‡†åŒ–**

```python
def _fit_scaler(self, df: pd.DataFrame) -> StandardScaler:
    # è·å–æ‰€æœ‰æ•°å€¼ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in METADATA_COLUMNS + ['timestamp']]

    scaler = StandardScaler()
    scaler.fit(df[feature_cols])
    return scaler

def _transform_data(self, df: pd.DataFrame, scaler: StandardScaler) -> pd.DataFrame:
    # è·å–æ‰€æœ‰æ•°å€¼ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in METADATA_COLUMNS + ['timestamp']]

    # è½¬æ¢ç‰¹å¾
    scaled_features = scaler.transform(df[feature_cols])

    # åˆ›å»ºæ–°çš„DataFrame
    result_df = df.copy()
    result_df[feature_cols] = scaled_features
    return result_df
```

### 4. **EMSHAPè¾“å…¥å‡†å¤‡**

åœ¨è®­ç»ƒè„šæœ¬ä¸­ï¼Œæ•°æ®è¢«è½¬æ¢ä¸ºEMSHAPçš„è¾“å…¥æ ¼å¼ï¼š

```python
def load_and_preprocess_data(data_path: str) -> tuple:
    """Load and preprocess data"""
    logger.info(f"Loading data: {data_path}")

    # è¯»å–æ•°æ®
    df = pd.read_parquet(data_path)

    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    features = df[FEATURE_COLUMNS].values  # 20ç»´ç‰¹å¾å‘é‡
    labels = df[TARGET_COLUMN].values.reshape(-1, 1)  # åŠŸè€—æ ‡ç­¾

    logger.info(f"Data shape: features {features.shape}, labels {labels.shape}")
    return features, labels
```

### 5. **æ•°æ®ç”Ÿæˆè¿‡ç¨‹**

#### 5.1 **æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ**

```python
def generate_data_point(self, timestamp: datetime) -> FeatureVector:
    # 1. ç¡®å®šå·¥ä½œè´Ÿè½½æ¨¡å¼
    mode = self._get_workload_mode(timestamp)

    # 2. ç”ŸæˆåŸºç¡€æŒ‡æ ‡
    metrics = self._generate_workload_metrics(mode)

    # 3. è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    metrics.update(self._calculate_derived_metrics(metrics))

    # 4. è®¡ç®—åŠŸè€—
    power_consumption = self._calculate_power_consumption(metrics)

    # 5. åˆ›å»ºç‰¹å¾å‘é‡
    feature_vector = FeatureVector()
    feature_vector.time = int(timestamp.timestamp())
    feature_vector.node_id = self.node_id
    feature_vector.power_consumption = power_consumption

    # 6. å¡«å……æ‰€æœ‰ç‰¹å¾
    for key, value in metrics.items():
        setattr(feature_vector, key, float(value))

    return feature_vector
```

### 6. **æœ€ç»ˆEMSHAPè¾“å…¥æ ¼å¼**

ç»è¿‡é¢„å¤„ç†åï¼ŒEMSHAPæ¥æ”¶çš„è¾“å…¥æ ¼å¼ä¸ºï¼š

```python
# è¾“å…¥ç‰¹å¾çŸ©é˜µ: (batch_size, 20)
features = df[FEATURE_COLUMNS].values

# ç›®æ ‡æ ‡ç­¾: (batch_size, 1)  
labels = df[TARGET_COLUMN].values.reshape(-1, 1)

# EMSHAPæ¨¡å‹è¾“å…¥
model_input = torch.FloatTensor(features)  # 20ç»´ç‰¹å¾å‘é‡
```

## 7. ç‰¹å¾å‘é‡è½¬æ¢æ€»ç»“

### **è½¬æ¢æ­¥éª¤**ï¼š

1. **åŸå§‹æ•°æ®æ”¶é›†** â†’ 22ä¸ªå­—æ®µçš„æ€§èƒ½æŒ‡æ ‡
2. **æ•°æ®æ¸…æ´—** â†’ å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
3. **ç‰¹å¾å·¥ç¨‹** â†’ æ·»åŠ æ—¶é—´ç‰¹å¾ã€æ»åç‰¹å¾ã€äº¤äº’ç‰¹å¾
4. **æ•°æ®æ ‡å‡†åŒ–** â†’ ä½¿ç”¨StandardScaleræ ‡å‡†åŒ–
5. **ç‰¹å¾é€‰æ‹©** â†’ æå–20ä¸ªæ ¸å¿ƒç‰¹å¾
6. **æ ¼å¼è½¬æ¢** â†’ è½¬æ¢ä¸ºnumpyæ•°ç»„/torchå¼ é‡

### **æœ€ç»ˆç‰¹å¾å‘é‡**ï¼š

- **ç»´åº¦**: 20ç»´
- **ç‰¹å¾ç±»å‹**: ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼ˆCPUã€å†…å­˜ã€GPUã€æ¸©åº¦ã€é£æ‰‡ç­‰ï¼‰
- **æ•°æ®æ ¼å¼**: æ ‡å‡†åŒ–åçš„æµ®ç‚¹æ•°
- **æ—¶é—´åºåˆ—**: æ”¯æŒæ—¶é—´åºåˆ—å»ºæ¨¡

è¿™ç§è®¾è®¡ç¡®ä¿äº†EMSHAPæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ä¸åŠŸè€—ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œå¹¶é€šè¿‡Shapleyå€¼åˆ†ææ¯ä¸ªç‰¹å¾å¯¹åŠŸè€—é¢„æµ‹çš„è´¡çŒ®åº¦ã€‚
